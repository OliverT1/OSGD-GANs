{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSGD - GAN Project - MNIST Fashion\n",
    "\n",
    "\n",
    "## Contents\n",
    "1. Setup\n",
    "2. Loading The Data\n",
    "3. Defining the GAN Class\n",
    "4. Instantiating a GAN\n",
    "5. Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "\n",
    "import math \n",
    "import seaborn as sns # To plot graphs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(        # Gets the train_set from FashionMNIST\n",
    "    root = './data/FashionMNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display images\n",
    "def show_images(images_arry,num_images_to_show,title):\n",
    "    # Imput: images_arry, an array of tensors to display as images; num_images_to_show, integer representing num images to show\n",
    "    # Output: prints images as output\n",
    "    \n",
    "    n = np.min([len(images_arry),num_images_to_show]) # Number of images to display\n",
    "    fig, ax = plt.subplots(1,n) # Makes an array of subplot objects \n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    for index in range(n):\n",
    "        ax[index].imshow(images_arry[index].squeeze(), cmap='gray_r'); # Investigate the cmap\n",
    "        ax[index].axis('off')  # clear x-axis and y-axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's see what this data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_loader = torch.utils.data.DataLoader(train_set, batch_size=5, shuffle=True)\n",
    "temp_dataiter = iter(temp_data_loader)\n",
    "images,labels = temp_dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_images(images,5,'Fashion_MNIST')\n",
    "print(images[0].size())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can use a train loader to batch our images. IMPORTANT: images are 1 x 28 x 28 tensors with vals in [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining the GAN Class"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We use the GAN code from the previous notebook, but chainging the training function to only take in one minibatch. This then allows us to use the DATALOADER (in Pytorch) to efficiently load data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self,ModuleList):\n",
    "        # Input: a torch.nn.ModuleList object, specifying nn layers\n",
    "        # Output: Instanciates a nn object with the correct layers and activiation functions\n",
    "        \n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        self.layers = ModuleList # Sets network layers\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # Input: a tensor x, with size that agrees with the network\n",
    "        # Output: a tensor, the network evaluated on x\n",
    "        \n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones_target(n):\n",
    "    # Input: An integer n\n",
    "    # Output: Tensor of 1's size nx1\n",
    "    \n",
    "    return Variable(torch.ones(n,1))\n",
    "    \n",
    "def zeros_target(n):\n",
    "    # Input: An integer n\n",
    "    # Output: Tensor of 0's size nx1\n",
    "    \n",
    "    return Variable(torch.zeros(n,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self,d_ModuleList,g_ModuleList,data_dim,latent_dim):\n",
    "        # Input: d_ModuleList,g_ModuleList are torch.nn.ModuleLists, data_dim is a tuple, latent_dim is a tuple\n",
    "        # Output: Instance of GAN class \n",
    "        \n",
    "        # Instantiate the discriminator & generator\n",
    "        self.discriminator = NeuralNetwork(d_ModuleList)\n",
    "        self.generator = NeuralNetwork(g_ModuleList)\n",
    "        \n",
    "        self.data_dim = data_dim # Number of inputs into discriminator = dimention of data, as a tuple\n",
    "        self.latent_dim = latent_dim # Number of inputs into generator = dimention of latent space\n",
    "    \n",
    "    def update_discriminator(self,real_data,generated_data):\n",
    "        # Input: real_data (minibatch from real data set) ,generated_data (minibatch made by generator)\n",
    "        # Output: discriminator's loss and mean predictions for real and generated data\n",
    "        \n",
    "        # Initial setup/clearing of gradients\n",
    "        self.d_optimiser.zero_grad()\n",
    "        loss = nn.BCELoss()\n",
    "        N,M = real_data.size(0),generated_data.size(0) # Number of data items in each sample\n",
    "        \n",
    "        # Apply discriminator to data entered (in order real then fake)\n",
    "        x = self.discriminator(torch.cat([real_data,generated_data]))\n",
    "        \n",
    "        # Create target labels (in order real then fake)\n",
    "        y = torch.cat([ones_target(N),zeros_target(M)])\n",
    "        \n",
    "        # Calculate loss and backprop\n",
    "        error = loss(x,y)\n",
    "        error.backward()\n",
    "        \n",
    "        # Update discriminator network\n",
    "        self.d_optimiser.step()\n",
    "        \n",
    "        # Return error and mean predictions\n",
    "        return error.detach().numpy(), torch.mean(x[:N].detach()).numpy(),torch.mean(x[-M:].detach()).numpy()\n",
    "        \n",
    "    def update_generator(self,generated_data):\n",
    "        # Input: generated_data (minibatch made by generator)\n",
    "        # Output: generators' loss\n",
    "        \n",
    "        # Initial setup/clearing of gradients\n",
    "        self.g_optimiser.zero_grad()\n",
    "        loss = nn.BCELoss()\n",
    "        M = generated_data.size(0)\n",
    "        \n",
    "        # Apply discriminator to data entered\n",
    "        x = self.discriminator(generated_data)\n",
    "        \n",
    "        # Create target labels\n",
    "        y = ones_target(M) # Want target to be 1's, opposite of disciminator's aim\n",
    "        \n",
    "        # Calculate loss and backprop\n",
    "        error = loss(x,y)\n",
    "        error.backward()\n",
    "        \n",
    "        # Update generator network\n",
    "        self.g_optimiser.step()\n",
    "        \n",
    "        # Return error\n",
    "        return error.detach().numpy() \n",
    "    \n",
    "    def batch_train(self,data_batch,d_learning_rate,g_learning_rate):\n",
    "        # Input: data_batch (in a tensor size 1 by n),d_learning_rate/g_learning_rate, learning rates for each nn\n",
    "        # Output: returns progress info, updates discriminator and generator networks\n",
    "        \n",
    "        # Sets optimisers\n",
    "        self.d_optimiser = optim.Adam(self.discriminator.parameters(), d_learning_rate)\n",
    "        self.g_optimiser = optim.Adam(self.generator.parameters(), g_learning_rate)\n",
    "        \n",
    "        k = 1 # Number of steps to apply to the discriminator, In original paper this variable is assigned to 1\n",
    "        n = data_batch.size(0) # Number of data items in  batch\n",
    "\n",
    "        for i in range(k):\n",
    "            # Reshape real data if needed\n",
    "            data_batch = data_batch.reshape((n,)+self.data_dim)\n",
    "            \n",
    "            # Get batch of fake data from generator\n",
    "            generated_data = self.generate(n) # Same size as real_data, detatch so generator gradient not affected\n",
    "            \n",
    "            # Optimise discriminator\n",
    "            d_error,avg_real_pred,avg_fake_pred = self.update_discriminator(data_batch,generated_data.detach())\n",
    "            \n",
    "            \n",
    "        # Optimise generator, with new batch of generated data\n",
    "        generated_data = self.generate(n) # Need new data here as discriminator has been trained on the 'old' generated_data\n",
    "        g_error = self.update_generator(generated_data)\n",
    "        \n",
    "        return g_error,d_error,avg_real_pred,avg_fake_pred\n",
    "            \n",
    "    def noise(self,n):\n",
    "    # Input: An integer n, the number of samples to make\n",
    "    # Output: A tensor of size nxdims of random values\n",
    "\n",
    "        return Variable(torch.randn((n,)+self.latent_dim))\n",
    "    \n",
    "    def generate(self,n):\n",
    "        # Input: n (number of values to geneerate)\n",
    "        # Output: n generated data items from the generator\n",
    "        \n",
    "        return self.generator(self.noise(n)).view((n,)+self.data_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Instantiating a GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are two cells, one using a CNN, one using an linear nn. Just comment one out and turn the other one into code to swap back and forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_GAN = GAN(nn.ModuleList([\n",
    "                    nn.Sequential(                     # Module list for discriminator\n",
    "                        nn.Linear(784, 1024),\n",
    "                        nn.LeakyReLU(0.2),\n",
    "                        nn.Dropout(0.3),\n",
    "                        \n",
    "                        nn.Linear(1024, 512),\n",
    "                        nn.LeakyReLU(0.2),\n",
    "                        nn.Dropout(0.3),\n",
    "\n",
    "                        nn.Linear(512, 256),\n",
    "                        nn.LeakyReLU(0.2),\n",
    "                        nn.Dropout(0.3),\n",
    "                        \n",
    "                        torch.nn.Linear(256, 1),\n",
    "                        torch.nn.Sigmoid()\n",
    "                    )]),\n",
    "                  nn.ModuleList([                      # Module list for generator\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(200,256),\n",
    "                        nn.LeakyReLU(0.1),\n",
    "                        nn.Dropout(0.3),\n",
    "\n",
    "                        nn.Linear(256,512),\n",
    "                        nn.LeakyReLU(0.1),\n",
    "                        nn.Dropout(0.3),\n",
    "\n",
    "                        nn.Linear(512,1024),\n",
    "                        nn.LeakyReLU(0.1),\n",
    "\n",
    "                        nn.Linear(1024,784),\n",
    "                        torch.nn.Sigmoid()\n",
    "                    )]),\n",
    "                  (784,),                              # Tuple representing data dim into discriminator\n",
    "                  (200,))                              # Tuple representing latent dim into generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fashion_GAN = GAN(nn.ModuleList([                      # Module list for discriminator\n",
    "                    nn.Sequential(\n",
    "                        nn.Conv2d(1, 128, kernel_size=3, padding=0),\n",
    "                        nn.ReLU(),\n",
    "                        nn.MaxPool2d(2),\n",
    "                        \n",
    "                        nn.Conv2d(128, 128, kernel_size=3, padding=0),\n",
    "                        nn.ReLU(),\n",
    "                        \n",
    "                        nn.Flatten(),\n",
    "                        \n",
    "                        nn.Linear(128*11*11,1),\n",
    "                        torch.nn.Sigmoid()\n",
    "                    )]),\n",
    "                  nn.ModuleList([                      # Module list for generator\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(100,256),\n",
    "                        nn.LeakyReLU(0.1),\n",
    "                        nn.Dropout(0.3),\n",
    "\n",
    "                        nn.Linear(256,512),\n",
    "                        nn.LeakyReLU(0.1),\n",
    "                        nn.Dropout(0.3),\n",
    "\n",
    "                        nn.Linear(512,1024),\n",
    "                        nn.LeakyReLU(0.1),\n",
    "\n",
    "                        nn.Linear(1024,784),\n",
    "                        torch.nn.Sigmoid()\n",
    "                    )]),\n",
    "                  (1,28,28),                           # Tuple representing data dim into discriminator\n",
    "                  (100,))                              # Tuple representing latent dim into generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Training Constants\n",
    "N_EPOCHS = 5\n",
    "d_lr = 0.0001*0.02\n",
    "g_lr = 0.02\n",
    "\n",
    "# Log info with no training\n",
    "print(\"Training = \"+str(0)+\" % Complete:\")\n",
    "sample = torch.Tensor(fashion_GAN.generate(7).detach()).view(7,1,28,28)\n",
    "show_images(sample,7,\"EPOCH \"+str(0))\n",
    "\n",
    "for e in range(1,N_EPOCHS+1):\n",
    "    for i, (images,labels) in enumerate(data_loader):\n",
    "        g_error,d_error,avg_real_pred,avg_fake_pred = fashion_GAN.batch_train(images,d_lr,g_lr) #d lr then g lr\n",
    "\n",
    "        # EPOCH Progress info\n",
    "        epoch_progress = round(i*1000/len(data_loader))/10\n",
    "        if (epoch_progress) % 20 == 0:\n",
    "            print(\"\\tEPOCH \"+str(epoch_progress)+\"% Complete:\")\n",
    "            print(\"\\t\\t Generator Loss =     \"+str(g_error))\n",
    "            print(\"\\t\\t Discriminator Loss = \"+str(d_error))\n",
    "            \n",
    "            print(\"\\t\\t\\t avg prediction on real data = \"+str(avg_real_pred)) # Prints avg predictions on real data (discrim wants this to be 1, we want 0.5)\n",
    "            print(\"\\t\\t\\t avg prediction on fake data = \"+str(avg_fake_pred)) # Prints avg predictions on fake data (discrim wants this to be 0, we want 0.5)\n",
    "     \n",
    "            # Display Sample Images\n",
    "            sample = (fashion_GAN.generate(7).detach()).view(7,1,28,28)\n",
    "            show_images(sample,7,\"EPOCH \"+str(e))\n",
    "    \n",
    "    # Overall Progress       \n",
    "    print(\"Training = \"+str(100*e/N_EPOCHS)+\" % Complete:\")\n",
    "    \n",
    "end = time.time()\n",
    "print('Total Training Time = ',str(end - start)/60 + \" mins\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
